{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3959122b",
   "metadata": {},
   "source": [
    "# Vision Zero, Chicago, modeling car crashes with injuries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52999b83",
   "metadata": {},
   "source": [
    "# Overview\n",
    "I was hired by a government agency CMAP (Chicago Metropolitan Agency for Planning) to create a model which predicts injuries during car crashes based on information collected by Chicago Police Department (CPD). I  concluded that there are many features that determine the oucome of car crash(overall 200 features, only 31 were used in our model), some of them: type of crash , day, season, time, type of crash, are there injuried people, phyesical imparement factors(drugs, alchogol, distraction etc), speed limit, weather, lightning and road conditions etc .\n",
    "\n",
    "To acheive my goal, I trained more than 100 models and tuned hyperparameters, model types that were used: \n",
    "- LogisticRegression\n",
    "- KNN\n",
    "- Naive Bayes(different type) \n",
    "- DecisionTree\n",
    "- Random Forest\n",
    "- ADA Boost\n",
    "- Gradient boost\n",
    "- XGB Classifier\n",
    "\n",
    "\n",
    "# Business Understanding\n",
    "Our stakeholder wants to understand what factors of crash influence on injury outcome as the last possible outcome. They perfectly understand that car crashes will be happening but they want to reduce the number of injuries because individual health prevails under public mobility. \n",
    "\n",
    "# Data\n",
    "\n",
    "1) Database Traffic Crashes - Crashes. Years: 2017 - now\n",
    "Provided by City of Chicago\n",
    "\n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if \n",
    "\n",
    "2) Database Traffic Crashes - People. Years: 2017 - now\n",
    "Provided by City of Chicago\n",
    "\n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-People/u6pd-qa9d\n",
    "\n",
    "3) Database Traffic Crashes - Vehicles. Years: 2017 - now\n",
    "Provided by City of Chicago  \n",
    "\n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-Vehicles/68nd-jvt3\n",
    "\n",
    "##### In my research I used data for 2021 year.\n",
    "\n",
    "# Metrics\n",
    "#### Our project will answer following question:\n",
    "What factors influence injuries?\n",
    "\n",
    "#### Hypothesis:\n",
    "H0 - car crashes with injuries are random\n",
    "\n",
    "HA - There is a significant dependancy between injuries and the features of dataset\n",
    "\n",
    "#### TP, TN, FP, FN definition\n",
    "TP - we predict car crash with injury and it actually happened.\n",
    "\n",
    "TN - we predicted that there is no injury and there was no injury,\n",
    "\n",
    "FP - We predicted injury but there was no injury in real life\n",
    "\n",
    "FN - We predicted that there will be no injury but it happened\n",
    "\n",
    "\n",
    "#### Metrics used  \n",
    "To compare models we will focus on 2 major metrics:\n",
    "\n",
    "Accuracy - how good we can predict TP and TN. General metrics that will show model performance.\n",
    "\n",
    "Recall - Health of people is our priority, we will be focused to minimize FN, so we can consider as much real car crashes with injuries in our model as possible, even if our model mark some car crashes with injuries but there will be no such. From the other side we need consider accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcdcd20",
   "metadata": {},
   "source": [
    "\n",
    "# Data Understanding\n",
    "#### Sources of data:\n",
    "1) Database Traffic Crashes - Crashes. Years: 2017 - now\n",
    "Covers: Main characteristics of car crash.\n",
    "Provided by City of Chicago \n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if\n",
    "\n",
    "2) Database Traffic Crashes - People. Years: 2017 - now\n",
    "Covers: People/drivers involved in car crash.\n",
    "Provided by City of Chicago \n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-People/u6pd-qa9d\n",
    "\n",
    "3) Database Traffic Crashes - Vehicles. Years: 2017 - now\n",
    "Covers: Vehicles involved in car crash.\n",
    "Provided by City of Chicago \n",
    "https://data.cityofchicago.org/Transportation/Traffic-Crashes-Vehicles/68nd-jvt3\n",
    "\n",
    "#### Main dataset contains the following columns:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24102ee3",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0985f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as stats\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Modeling\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, roc_curve, plot_roc_curve, roc_auc_score, accuracy_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "#Other\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import os, shutil \n",
    "from zipfile import ZipFile\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "simplefilter(action='ignore', category= FutureWarning)\n",
    "simplefilter(action='ignore', category= ConvergenceWarning)\n",
    "simplefilter(action='ignore', category= FitFailedWarning)\n",
    "simplefilter(action='ignore', category= UserWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508df54",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ffa69",
   "metadata": {},
   "source": [
    "Below we create three objects representing the existing directories: `data/normal/` as `data_normal_dir` and `data/pneumonia/` as `data_pneumonia_dir`, `data/test/normal/` as `test/normal` and `data/test/pneumonia/` as `test/pneumonia`. We will create a new directory `split/` as `new_dir`, where we will split the dataset in three groups (or three subdirectories): `train`, `test`, and `validation`, each containing `normal` and `pneumonia` subfolders. The final desired structure is represented below: \n",
    "\n",
    "![title](images/folder_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796cf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal_dir = 'data/normal/'\n",
    "data_pneumonia_dir = 'data/pneumonia/'\n",
    "new_dir = 'data/split/'\n",
    "data_test_normal_dir = 'data/test/normal/'\n",
    "data_test_pneumonia_dir = 'data/test/pneumonia/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ae3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb0a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "imgs_normal = [file for file in os.listdir(data_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_pneumonia = [file for file in os.listdir(data_pneumonia_dir) if file.endswith('.jpeg')]\n",
    "# Test set\n",
    "imgs_normal_test = [file for file in os.listdir(data_test_normal_dir) if file.endswith('.jpeg')]\n",
    "imgs_pneumonia_test = [file for file in os.listdir(data_test_pneumonia_dir) if file.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3167606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NORMAL-2552119-0002.jpeg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_normal_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c128a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "There are 620 normal images, image name example, NORMAL-2552119-0002.jpeg\n",
      "There are 667 pneumonia images, image name example, BACTERIA-292199-0002.jpeg\n",
      "Test set:\n",
      "There are 234 normal images, image name example, NORMAL-8698006-0001.jpeg\n",
      "There are 390 pneumonia images, image name example, VIRUS-2040583-0001.jpeg\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set:\")\n",
    "print('There are', len(imgs_normal), 'normal images, image name example,',os.listdir(data_normal_dir)[0])\n",
    "print('There are', len(imgs_pneumonia), 'pneumonia images, image name example,',os.listdir(data_pneumonia_dir)[0])\n",
    "print(\"Test set:\")\n",
    "print('There are', len(imgs_normal_test), 'normal images, image name example,',os.listdir(data_test_normal_dir)[0])\n",
    "print('There are', len(imgs_pneumonia_test), 'pneumonia images, image name example,',os.listdir(data_test_pneumonia_dir)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d949deb4",
   "metadata": {},
   "source": [
    "Make new split directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c230137",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c26936",
   "metadata": {},
   "source": [
    "Create new directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649703d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "train_folder = os.path.join(new_dir, 'train')\n",
    "train_normal = os.path.join(train_folder, 'normal')\n",
    "train_pneumonia = os.path.join(train_folder, 'pneumonia')\n",
    "\n",
    "test_folder = os.path.join(new_dir, 'test')\n",
    "test_normal = os.path.join(test_folder, 'normal')\n",
    "test_pneumonia = os.path.join(test_folder, 'pneumonia')\n",
    "\n",
    "val_folder = os.path.join(new_dir, 'validation')\n",
    "val_normal = os.path.join(val_folder, 'normal')\n",
    "val_pneumonia = os.path.join(val_folder, 'pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48d44a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/split/train/pneumonia'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that path is ok\n",
    "train_pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3fe667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.mkdir(test_folder)\n",
    "os.mkdir(test_normal)\n",
    "os.mkdir(test_pneumonia)\n",
    "\n",
    "os.mkdir(train_folder)\n",
    "os.mkdir(train_normal)\n",
    "os.mkdir(train_pneumonia)\n",
    "\n",
    "os.mkdir(val_folder)\n",
    "os.mkdir(val_normal)\n",
    "os.mkdir(val_pneumonia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2bd38",
   "metadata": {},
   "source": [
    "Copy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863cf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting size of validation set\n",
    "val_set = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225c75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3743339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train normal\n",
    "imgs_train_norm = imgs_normal[:len(os.listdir(data_normal_dir))-val_set]\n",
    "for img in imgs_train_norm:\n",
    "    origin = os.path.join(data_normal_dir, img)\n",
    "    destination = os.path.join(train_normal, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# train pneumonia\n",
    "imgs_train_pneumonia = imgs_pneumonia[:len(os.listdir(data_pneumonia_dir))-val_set]\n",
    "for img in imgs_train_pneumonia:\n",
    "    origin = os.path.join(data_pneumonia_dir, img)\n",
    "    destination = os.path.join(train_pneumonia, img)\n",
    "    shutil.copyfile(origin, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334e1cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs_train_pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50067fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation santa\n",
    "imgs = imgs_normal[len(os.listdir(data_normal_dir))-val_set:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_normal_dir, img)\n",
    "    destination = os.path.join(val_normal, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "\n",
    "imgs = imgs_pneumonia[len(os.listdir(data_normal_dir))-val_set:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_pneumonia_dir, img)\n",
    "    destination = os.path.join(val_pneumonia, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da465b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normal\n",
    "imgs = imgs_normal_test\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_test_normal_dir, img)\n",
    "    destination = os.path.join(test_normal, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# test pneumonia\n",
    "imgs = imgs_pneumonia_test\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_test_pneumonia_dir, img)\n",
    "    destination = os.path.join(test_pneumonia, img)\n",
    "    shutil.copyfile(origin, destination)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373674f4",
   "metadata": {},
   "source": [
    "Check the folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2c5f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train images\n",
    "train_img_number = len(os.listdir(train_normal)) + len(os.listdir(train_pneumonia))\n",
    "# Validation images\n",
    "val_img_number = len(os.listdir(val_normal)) + len(os.listdir(val_pneumonia))\n",
    "# Test images\n",
    "test_img_number = len(os.listdir(test_normal)) + len(os.listdir(test_pneumonia))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba9e475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 987 images\n",
      "There are 470 normal images in the training set\n",
      "There are 517 pneumonia images in the training set\n",
      "Validation set: 347 images\n",
      "There are 150 normal images in the validation set\n",
      "There are 197 pneumonia images in the validation set\n",
      "Test set: 624 images\n",
      "There are 234 normal images in the test set\n",
      "There are 390 pneumonia images in the test set\n"
     ]
    }
   ],
   "source": [
    "print('Training set:',train_img_number, \"images\" )\n",
    "print('There are', len(os.listdir(train_normal)), 'normal images in the training set')\n",
    "print('There are', len(os.listdir(train_pneumonia)), 'pneumonia images in the training set')\n",
    "print('Validation set:', val_img_number, \"images\" )\n",
    "print('There are', len(os.listdir(val_normal)), 'normal images in the validation set')\n",
    "print('There are', len(os.listdir(val_pneumonia)), 'pneumonia images in the validation set')\n",
    "print('Test set:', test_img_number, 'images')\n",
    "print('There are', len(os.listdir(test_normal)), 'normal images in the test set')\n",
    "print('There are', len(os.listdir(test_pneumonia)), 'pneumonia images in the test set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cc30a",
   "metadata": {},
   "source": [
    "### Use a densely connected network as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "258a7446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 987 images belonging to 2 classes.\n",
      "Found 347 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/train (987 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(299, 299), batch_size=987)\n",
    "\n",
    "# get all the data in the directory split/validation (347 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(299, 299), batch_size = 347)\n",
    "\n",
    "# get all the data in the directory split/test (624 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(299, 299), batch_size = 624) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "351551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11de78c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 987\n",
      "Number of testing samples: 624\n",
      "Number of validation samples: 347\n",
      "train_images shape: (987, 299, 299, 3)\n",
      "train_labels shape: (987, 2)\n",
      "test_images shape: (624, 299, 299, 3)\n",
      "test_labels shape: (624, 2)\n",
      "val_images shape: (347, 299, 299, 3)\n",
      "val_labels shape: (347, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab41c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(987, 268203)\n",
      "(624, 268203)\n",
      "(347, 268203)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea35786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (train_img_number,1))\n",
    "test_y = np.reshape(test_labels[:,0], (test_img_number,1))\n",
    "val_y = np.reshape(val_labels[:,0], (val_img_number,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4096dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:31:49.119554: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(train_img.shape[1],))) # 2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 8s 172ms/step - loss: 1.2229 - accuracy: 0.5127 - val_loss: 0.6921 - val_accuracy: 0.5677\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 0.6928 - accuracy: 0.5238 - val_loss: 0.6916 - val_accuracy: 0.5677\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 2s 77ms/step - loss: 0.6927 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5677\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 2s 80ms/step - loss: 0.6926 - accuracy: 0.5238 - val_loss: 0.6908 - val_accuracy: 0.5677\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.6925 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5677\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 3s 92ms/step - loss: 0.6924 - accuracy: 0.5238 - val_loss: 0.6902 - val_accuracy: 0.5677\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 0.6923 - accuracy: 0.5238 - val_loss: 0.6900 - val_accuracy: 0.5677\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.6923 - accuracy: 0.5238 - val_loss: 0.6897 - val_accuracy: 0.5677\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 3s 95ms/step - loss: 0.6922 - accuracy: 0.5238 - val_loss: 0.6895 - val_accuracy: 0.5677\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 0.6922 - accuracy: 0.5238 - val_loss: 0.6893 - val_accuracy: 0.5677\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 2s 78ms/step - loss: 0.6922 - accuracy: 0.5238 - val_loss: 0.6892 - val_accuracy: 0.5677\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 0.6922 - accuracy: 0.5238 - val_loss: 0.6890 - val_accuracy: 0.5677\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6889 - val_accuracy: 0.5677\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6888 - val_accuracy: 0.5677\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6887 - val_accuracy: 0.5677\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6886 - val_accuracy: 0.5677\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6885 - val_accuracy: 0.5677\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6885 - val_accuracy: 0.5677\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6884 - val_accuracy: 0.5677\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6884 - val_accuracy: 0.5677\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 4s 113ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6883 - val_accuracy: 0.5677\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6883 - val_accuracy: 0.5677\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6882 - val_accuracy: 0.5677\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 3s 97ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6882 - val_accuracy: 0.5677\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6882 - val_accuracy: 0.5677\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 0.6920 - accuracy: 0.5238 - val_loss: 0.6882 - val_accuracy: 0.5677\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6881 - val_accuracy: 0.5677\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6881 - val_accuracy: 0.5677\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 3s 106ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6881 - val_accuracy: 0.5677\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 3s 98ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 3s 102ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 3s 96ms/step - loss: 0.6921 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 3s 107ms/step - loss: 0.6920 - accuracy: 0.5238 - val_loss: 0.6880 - val_accuracy: 0.5677\n",
      "Epoch 37/50\n",
      " 2/31 [>.............................] - ETA: 2s - loss: 0.6928 - accuracy: 0.5156"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3468e98",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "---\n",
    "For our finalized model we used LinearRegression because of the following reasons: \n",
    "1) It is easy to interprete.\n",
    "\n",
    "2) It have good recall compared to the other models, without much sacrifice in precision. \n",
    "\n",
    "\n",
    "Overall, this data tells us that injuries during car crashes can be predicted and we can see tha major factors that influence it. These modeling results correspond to our observations during data exploration phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
